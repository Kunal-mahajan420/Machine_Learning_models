{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import libraries\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %pip install tf-nightly\n",
        "except Exception:\n",
        "  pass\n",
        "%pip install tensorflow-datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RZOuS9LWQvv",
        "outputId": "ae28f096-ebbc-41ab-db10-9edb2b42b7e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tf-nightly\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b5/1f/604a92fca42ecfd05a91433ddea0b4decb6ec9e4f13452be53834f16e6f9/tf_nightly-2.6.0.dev20210521-cp37-cp37m-manylinux2010_x86_64.whl (448.7MB)\n",
            "\u001b[K     |████████████████████████████████| 448.7MB 35kB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (3.3.0)\n",
            "Collecting tb-nightly~=2.6.0.a\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/03/6189b95e396b147f4cc9afaa8f18c56d76390f548a5de9f329411b21528d/tb_nightly-2.6.0a20210521-py3-none-any.whl (5.9MB)\n",
            "\u001b[K     |████████████████████████████████| 5.9MB 40.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.19.5)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (0.12.0)\n",
            "Collecting h5py~=3.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/74/9eae2bedd8201ab464308f42c601a12d79727a1c87f0c867fdefb212c6cf/h5py-3.1.0-cp37-cp37m-manylinux1_x86_64.whl (4.0MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0MB 44.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.12)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.6.3)\n",
            "Collecting tf-estimator-nightly~=2.5.0.dev\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/6c/9bf4a6004d18c8e543845d3416e50f36dd09d272161e2fb0db5678132dfd/tf_estimator_nightly-2.5.0.dev2021032601-py2.py3-none-any.whl (462kB)\n",
            "\u001b[K     |████████████████████████████████| 471kB 50.7MB/s \n",
            "\u001b[?25hCollecting grpcio<2.0,>=1.37.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/af/ecae3a21bed5a92c9d866480553efea18a39f103546108cd60f5ea6a2494/grpcio-1.38.0-cp37-cp37m-manylinux2014_x86_64.whl (4.2MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2MB 42.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (0.36.2)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.1.2)\n",
            "Collecting gast==0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/b6/48/583c032b79ae5b3daa02225a675aeb673e58d2cb698e78510feceb11958c/gast-0.4.0-py3-none-any.whl\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.1.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (0.2.0)\n",
            "Collecting keras-nightly~=2.6.0.dev\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/a2/83c7d344fad337c2338039902e82e0e95fba59128da032092cba0373f00a/keras_nightly-2.6.0.dev2021052100-py2.py3-none-any.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 41.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (3.7.4.3)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.15.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tf-nightly) (1.12.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.6.0.a->tf-nightly) (2.0.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.6.0.a->tf-nightly) (1.30.0)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/f9/802efd84988bffd9f644c03b6e66fde8e76c3aa33db4279ddd11c5d61f4b/tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9MB 43.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.6.0.a->tf-nightly) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.6.0.a->tf-nightly) (0.4.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.6.0.a->tf-nightly) (1.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.6.0.a->tf-nightly) (3.3.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tb-nightly~=2.6.0.a->tf-nightly) (56.1.0)\n",
            "Collecting cached-property; python_version < \"3.8\"\n",
            "  Downloading https://files.pythonhosted.org/packages/48/19/f2090f7dad41e225c7f2326e4cfe6fff49e57dedb5b53636c9551f86b069/cached_property-1.5.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tb-nightly~=2.6.0.a->tf-nightly) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tb-nightly~=2.6.0.a->tf-nightly) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tb-nightly~=2.6.0.a->tf-nightly) (4.7.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.6.0.a->tf-nightly) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.6.0.a->tf-nightly) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.6.0.a->tf-nightly) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tb-nightly~=2.6.0.a->tf-nightly) (3.0.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.6.0.a->tf-nightly) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tb-nightly~=2.6.0.a->tf-nightly) (4.0.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tb-nightly~=2.6.0.a->tf-nightly) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.6.0.a->tf-nightly) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tb-nightly~=2.6.0.a->tf-nightly) (3.4.1)\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement gast==0.3.3, but you'll have gast 0.4.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement grpcio~=1.32.0, but you'll have grpcio 1.38.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement h5py~=2.10.0, but you'll have h5py 3.1.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: grpcio, tensorboard-data-server, tb-nightly, cached-property, h5py, tf-estimator-nightly, gast, keras-nightly, tf-nightly\n",
            "  Found existing installation: grpcio 1.32.0\n",
            "    Uninstalling grpcio-1.32.0:\n",
            "      Successfully uninstalled grpcio-1.32.0\n",
            "  Found existing installation: h5py 2.10.0\n",
            "    Uninstalling h5py-2.10.0:\n",
            "      Successfully uninstalled h5py-2.10.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "Successfully installed cached-property-1.5.2 gast-0.4.0 grpcio-1.38.0 h5py-3.1.0 keras-nightly-2.6.0.dev2021052100 tb-nightly-2.6.0a20210521 tensorboard-data-server-0.6.1 tf-estimator-nightly-2.5.0.dev2021032601 tf-nightly-2.6.0.dev20210521\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (4.0.1)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets) (2.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets) (1.19.5)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets) (3.12.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets) (4.41.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets) (2.23.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets) (0.1.6)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets) (0.30.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets) (0.12.0)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets) (21.2.0)\n",
            "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets) (5.1.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets) (0.16.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets) (0.3.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets) (1.15.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets) (1.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow-datasets) (56.1.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow-datasets) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow-datasets) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow-datasets) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tensorflow-datasets) (2020.12.5)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tensorflow-datasets) (1.53.0)\n",
            "Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-resources; python_version < \"3.9\"->tensorflow-datasets) (3.4.1)\n",
            "2.6.0-dev20210521\n"
          ]
        }
      ],
      "source": [
        "# import libraries\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "import tensorflow_datasets as tfds\n",
        "from keras.utils import pad_sequences\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import re,nltk\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMHwYXHXCar3",
        "outputId": "0fdb7bff-33d9-4856-f8c7-f2e35a0589e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2021-05-21 18:04:31--  https://cdn.freecodecamp.org/project-data/sms/train-data.tsv\n",
            "Resolving cdn.freecodecamp.org (cdn.freecodecamp.org)... 104.26.3.33, 172.67.70.149, 104.26.2.33, ...\n",
            "Connecting to cdn.freecodecamp.org (cdn.freecodecamp.org)|104.26.3.33|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 358233 (350K) [text/tab-separated-values]\n",
            "Saving to: ‘train-data.tsv.2’\n",
            "\n",
            "\rtrain-data.tsv.2      0%[                    ]       0  --.-KB/s               \rtrain-data.tsv.2    100%[===================>] 349.84K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2021-05-21 18:04:31 (8.72 MB/s) - ‘train-data.tsv.2’ saved [358233/358233]\n",
            "\n",
            "--2021-05-21 18:04:31--  https://cdn.freecodecamp.org/project-data/sms/valid-data.tsv\n",
            "Resolving cdn.freecodecamp.org (cdn.freecodecamp.org)... 104.26.3.33, 172.67.70.149, 104.26.2.33, ...\n",
            "Connecting to cdn.freecodecamp.org (cdn.freecodecamp.org)|104.26.3.33|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 118774 (116K) [text/tab-separated-values]\n",
            "Saving to: ‘valid-data.tsv.2’\n",
            "\n",
            "valid-data.tsv.2    100%[===================>] 115.99K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2021-05-21 18:04:31 (5.04 MB/s) - ‘valid-data.tsv.2’ saved [118774/118774]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# get data files\n",
        "!wget https://cdn.freecodecamp.org/project-data/sms/train-data.tsv\n",
        "!wget https://cdn.freecodecamp.org/project-data/sms/valid-data.tsv\n",
        "\n",
        "train_file_path = \"train-data.tsv\"\n",
        "test_file_path = \"valid-data.tsv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSO7GMLq2Gg7",
        "outputId": "406e201c-552c-447c-bd5b-c356d89be5bb"
      },
      "outputs": [],
      "source": [
        "header=['s_class',\"msg\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_h508FEClxO"
      },
      "outputs": [],
      "source": [
        "df_train=pd.read_csv(train_file_path,delimiter='\\t',quoting=3,names=header)\n",
        "df_test=pd.read_csv(test_file_path,delimiter='\\t',quoting=3,names=header)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOMKywn4zReN",
        "outputId": "b545bf4e-5ebd-4709-e909-b3a3091d28a8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4179, 2)"
            ]
          },
          "execution_count": 83,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHZWxHI63aNf"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "df_train=df_train[['msg','s_class']]\n",
        "df_test=df_test[['msg','s_class']]\n",
        "df_train['s_class'] = df_train['s_class'].apply({'ham':0,'spam':1}.get) \n",
        "df_test['s_class'] = df_test['s_class'].apply({'ham':0,'spam':1}.get) \n",
        "\n",
        "\n",
        "y_train=np.array(df_train.pop('s_class'))\n",
        "y_test=np.array(df_test.pop('s_class'))_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DdCEwyOL3sO7"
      },
      "outputs": [],
      "source": [
        "corp_train=[]\n",
        "corp_test=[]\n",
        "for i in range(4179):\n",
        "  rvw=re.sub('[^A-Za-z0-9]',' ',df_train['msg'][i])\n",
        "  rvw=rvw.lower()\n",
        "  rvw=rvw.split()\n",
        "  stem_rvw=nltk.stem.porter.PorterStemmer()\n",
        "  rvw=[stem_rvw.stem(word) for word in rvw]\n",
        "  rvw=' '.join(rvw)\n",
        "  corp_train.append(rvw)\n",
        "  if(i<1392):\n",
        "    j=i\n",
        "    test_rvw=re.sub('[^A-Za-z0-9]',' ',df_test['msg'][j])\n",
        "    test_rvw=test_rvw.lower()\n",
        "    test_rvw=test_rvw.split()\n",
        "    test_stem=nltk.stem.porter.PorterStemmer()\n",
        "    test_rvw=[test_stem.stem(test_words) for test_words in test_rvw]\n",
        "    test_rvw=' '.join(test_rvw)\n",
        "    corp_test.append(test_rvw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgI6b8uA6WWu",
        "outputId": "ae794cf2-13bd-43c6-c7b9-b3a2540cc1b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hello darlin ive finish colleg now so txt me when u finish if u can love kate xxx\n",
            "[277, 732, 923, 209, 656, 22, 28, 76, 11, 53, 6, 209, 39, 6, 27, 61, 924, 381]\n",
            "6336\n"
          ]
        }
      ],
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "token=Tokenizer(num_words=5000)\n",
        "token.fit_on_texts(corp_train)\n",
        "\n",
        "x_train=token.texts_to_sequences(corp_train)\n",
        "x_test=token.texts_to_sequences(corp_test)\n",
        "\n",
        "voc_size=len(token.word_index)+1\n",
        "\n",
        "print(corp_train[10])\n",
        "print(x_train[10])\n",
        "print(voc_size)\n",
        "\n",
        "\n",
        "x_train = np.array(pad_sequences(x_train, padding='post', maxlen=90))\n",
        "x_test = np.array(pad_sequences(x_test, padding='post', maxlen=90))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqrzFqQ19LXW",
        "outputId": "51ee18ea-ba6f-499c-8661-a5dd90777e48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 90, 50)            316800    \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, 86, 128)           32128     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_4 (Glob (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 10)                1290      \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 350,229\n",
            "Trainable params: 350,229\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "\n",
        "embedding_dim = 50\n",
        "\n",
        "model = Sequential()\n",
        "model.add(layers.Embedding(input_dim=voc_size, \n",
        "                           output_dim=embedding_dim, \n",
        "                           input_length=90))\n",
        "model.add(layers.Conv1D(128, 5, activation='relu'))\n",
        "model.add(layers.GlobalMaxPool1D())\n",
        "model.add(layers.Dense(10, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzbBp4Xr9Q1P",
        "outputId": "0b292275-f9cd-4ef3-8a54-f01f5a3afaee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "418/418 [==============================] - 5s 11ms/step - loss: 0.1936 - accuracy: 0.9294 - val_loss: 0.0577 - val_accuracy: 0.9806\n",
            "Epoch 2/10\n",
            "418/418 [==============================] - 4s 10ms/step - loss: 0.0247 - accuracy: 0.9933 - val_loss: 0.0392 - val_accuracy: 0.9878\n",
            "Epoch 3/10\n",
            "418/418 [==============================] - 4s 10ms/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.0406 - val_accuracy: 0.9892\n",
            "Epoch 4/10\n",
            "418/418 [==============================] - 4s 10ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 0.0433 - val_accuracy: 0.9878\n",
            "Epoch 5/10\n",
            "418/418 [==============================] - 4s 10ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0458 - val_accuracy: 0.9871\n",
            "Epoch 6/10\n",
            "418/418 [==============================] - 4s 10ms/step - loss: 4.9917e-04 - accuracy: 1.0000 - val_loss: 0.0498 - val_accuracy: 0.9864\n",
            "Epoch 7/10\n",
            "418/418 [==============================] - 4s 10ms/step - loss: 1.3944e-04 - accuracy: 1.0000 - val_loss: 0.0518 - val_accuracy: 0.9871\n",
            "Epoch 8/10\n",
            "418/418 [==============================] - 4s 11ms/step - loss: 7.7657e-05 - accuracy: 1.0000 - val_loss: 0.0548 - val_accuracy: 0.9871\n",
            "Epoch 9/10\n",
            "418/418 [==============================] - 4s 10ms/step - loss: 5.1803e-05 - accuracy: 1.0000 - val_loss: 0.0574 - val_accuracy: 0.9871\n",
            "Epoch 10/10\n",
            "418/418 [==============================] - 4s 11ms/step - loss: 3.6798e-05 - accuracy: 1.0000 - val_loss: 0.0593 - val_accuracy: 0.9871\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(x_train,y_train,\n",
        "                    epochs=10,\n",
        "                    verbose=True,\n",
        "                    validation_data=(x_test,y_test), batch_size=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9tD9yACG6M9",
        "outputId": "7946cdd1-e654-4068-9b6b-eb2eff06ff28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[array([[9.4131865e-05]], dtype=float32), 'ham']\n"
          ]
        }
      ],
      "source": [
        "# function to predict messages based on model\n",
        "# (should return list containing prediction and label, ex. [0.008318834938108921, 'ham'])\n",
        "def predict_message(pred_text):\n",
        "  pred=[pred_text]\n",
        "  df_pred=pd.DataFrame(pred)\n",
        "  df_pred=df_pred.rename(columns={0:'msg',1:'s_class'})\n",
        "  corp_pred=[]\n",
        "  for i in range(0,len(pred)):\n",
        "    rvw=re.sub('[^A-Za-z0-9]',' ',df_pred['msg'][i])\n",
        "    rvw=rvw.lower()\n",
        "    rvw=rvw.split()\n",
        "    stem_rvw=nltk.stem.porter.PorterStemmer()\n",
        "    rvw=[stem_rvw.stem(word) for word in rvw]\n",
        "    rvw=' '.join(rvw)\n",
        "    corp_pred.append(rvw)\n",
        "    seq=token.texts_to_sequences(corp_pred)\n",
        "    seq=pad_sequences(seq,maxlen=90)\n",
        "    prediction=model.predict(seq)\n",
        "  if prediction>=0.5:\n",
        "    prediction=([prediction,'spam'])\n",
        "  else:\n",
        "    prediction=([prediction,'ham'])\n",
        "  return (prediction)\n",
        "\n",
        "pred_text = \"how are you doing today?\"\n",
        "\n",
        "prediction = predict_message(pred_text)\n",
        "print(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dxotov85SjsC",
        "outputId": "aaa45531-25f3-4b44-a5a7-0c43d4d83b39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You passed the challenge. Great job!\n"
          ]
        }
      ],
      "source": [
        "# Run this cell to test your function and model. Do not modify contents.\n",
        "def test_predictions():\n",
        "  test_messages = [\"how are you doing today\",\n",
        "                   \"sale today! to stop texts call 98912460324\",\n",
        "                   \"i dont want to go. can we try it a different day? available sat\",\n",
        "                   \"our new mobile video service is live. just install on your phone to start watching.\",\n",
        "                   \"you have won £1000 cash! call to claim your prize.\",\n",
        "                   \"i'll bring it tomorrow. don't forget the milk.\",\n",
        "                   \"wow, is your arm alright. that happened to me one time too\"\n",
        "                  ]\n",
        "\n",
        "  test_answers = [\"ham\", \"spam\", \"ham\", \"spam\", \"spam\", \"ham\", \"ham\"]\n",
        "  passed = True\n",
        "\n",
        "  for msg, ans in zip(test_messages, test_answers):\n",
        "    prediction = predict_message(msg)\n",
        "    if prediction[1] != ans:\n",
        "      passed = False\n",
        "\n",
        "  if passed:\n",
        "    print(\"You passed the challenge. Great job!\")\n",
        "  else:\n",
        "    print(\"You haven't passed yet. Keep trying.\")\n",
        "\n",
        "test_predictions()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
